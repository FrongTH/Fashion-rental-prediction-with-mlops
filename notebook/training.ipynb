{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read yaml file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config['DATA_PATH'] ## '../data/dress_rental_prices news.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>74416</td>\n",
       "      <td>Runway stripe dress</td>\n",
       "      <td>Stella McCartney</td>\n",
       "      <td>beige</td>\n",
       "      <td>dresses</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73815</td>\n",
       "      <td>Reformation Kourtney Dress</td>\n",
       "      <td>Reformation</td>\n",
       "      <td>beige</td>\n",
       "      <td>dresses</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>73801</td>\n",
       "      <td>Ivory Viola bridal dress</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>beige</td>\n",
       "      <td>dresses</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>73718</td>\n",
       "      <td>Pasu Dress - Rhino Tusk</td>\n",
       "      <td>Coucoo</td>\n",
       "      <td>beige</td>\n",
       "      <td>dresses</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73605</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>RIXO</td>\n",
       "      <td>beige</td>\n",
       "      <td>dresses</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numbers     ID                        Name             Brand Colour  \\\n",
       "0        0  74416         Runway stripe dress  Stella McCartney  beige   \n",
       "1        1  73815  Reformation Kourtney Dress       Reformation  beige   \n",
       "2        2  73801    Ivory Viola bridal dress             Ghost  beige   \n",
       "3        3  73718     Pasu Dress - Rhino Tusk            Coucoo  beige   \n",
       "4        4  73605                       Ellen              RIXO  beige   \n",
       "\n",
       "  Catagories  Price  \n",
       "0    dresses    111  \n",
       "1    dresses     50  \n",
       "2    dresses     75  \n",
       "3    dresses     37  \n",
       "4    dresses     47  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29997 entries, 0 to 29996\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   numbers     29997 non-null  int64 \n",
      " 1   ID          29997 non-null  int64 \n",
      " 2   Name        29995 non-null  object\n",
      " 3   Brand       29997 non-null  object\n",
      " 4   Colour      29997 non-null  object\n",
      " 5   Catagories  29997 non-null  object\n",
      " 6   Price       29997 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29997.000000</td>\n",
       "      <td>29997.000000</td>\n",
       "      <td>29997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>42548.336400</td>\n",
       "      <td>61.668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8659.532349</td>\n",
       "      <td>19867.282746</td>\n",
       "      <td>38.138688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2999.600000</td>\n",
       "      <td>14777.600000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>42902.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>26996.400000</td>\n",
       "      <td>68848.400000</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>28496.200000</td>\n",
       "      <td>71589.200000</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>29696.040000</td>\n",
       "      <td>73993.120000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29996.000000</td>\n",
       "      <td>75024.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            numbers            ID         Price\n",
       "count  29997.000000  29997.000000  29997.000000\n",
       "mean   14998.000000  42548.336400     61.668800\n",
       "std     8659.532349  19867.282746     38.138688\n",
       "min        0.000000    122.000000     11.000000\n",
       "10%     2999.600000  14777.600000     32.000000\n",
       "50%    14998.000000  42902.000000     51.000000\n",
       "90%    26996.400000  68848.400000    102.000000\n",
       "95%    28496.200000  71589.200000    139.000000\n",
       "99%    29696.040000  73993.120000    195.000000\n",
       "max    29996.000000  75024.000000    793.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[.1, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let see in exlore_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbers       0\n",
       "ID            0\n",
       "Name          2\n",
       "Brand         0\n",
       "Colour        0\n",
       "Catagories    0\n",
       "Price         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Name'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop numbers column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('numbers', axis= 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].astype('object')\n",
    "df['Brand'] = df['Brand'].astype('category')\n",
    "df['Colour'] = df['Colour'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split categories and replace nan with no-sub-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_categories = df['Catagories'].str.split(',', expand=True)\n",
    "sub_categories = sub_categories.fillna('no-sub-categories')\n",
    "sub_categories.columns = [f'sub-Catagories-{i+1}' for i in range(sub_categories.shape[1])]\n",
    "for sub in sub_categories.columns:\n",
    "    sub_categories[sub] = sub_categories[sub].astype('category')\n",
    "df = pd.concat([df, sub_categories], axis=1)\n",
    "df = df.drop(columns=['Catagories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter data with less than 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Price'] < 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average price by brand and add as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rattapon.San\\AppData\\Local\\Temp\\ipykernel_1192\\1663022941.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['Avg_Price_By_Brand'] = df.groupby('Brand')['Price'].transform('mean')\n"
     ]
    }
   ],
   "source": [
    "df['Avg_Price_By_Brand'] = df.groupby('Brand')['Price'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average price by (brand, colour) and add as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rattapon.San\\AppData\\Local\\Temp\\ipykernel_1192\\3750462187.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['Avg_Price_By_Brand_Colour'] = df.groupby(['Brand', 'Colour'])['Price'].transform('mean')\n"
     ]
    }
   ],
   "source": [
    "df['Avg_Price_By_Brand_Colour'] = df.groupby(['Brand', 'Colour'])['Price'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new column to count the number of sub-categories that are not 'no-sub-categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category_Count'] = (sub_categories != 'no-sub-categories').sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29974 entries, 0 to 29996\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   ID                         29974 non-null  object  \n",
      " 1   Name                       29974 non-null  object  \n",
      " 2   Brand                      29974 non-null  category\n",
      " 3   Colour                     29974 non-null  category\n",
      " 4   Price                      29974 non-null  int64   \n",
      " 5   sub-Catagories-1           29974 non-null  category\n",
      " 6   sub-Catagories-2           29974 non-null  category\n",
      " 7   sub-Catagories-3           29974 non-null  category\n",
      " 8   sub-Catagories-4           29974 non-null  category\n",
      " 9   sub-Catagories-5           29974 non-null  category\n",
      " 10  sub-Catagories-6           29974 non-null  category\n",
      " 11  sub-Catagories-7           29974 non-null  category\n",
      " 12  sub-Catagories-8           29974 non-null  category\n",
      " 13  sub-Catagories-9           29974 non-null  category\n",
      " 14  sub-Catagories-10          29974 non-null  category\n",
      " 15  sub-Catagories-11          29974 non-null  category\n",
      " 16  sub-Catagories-12          29974 non-null  category\n",
      " 17  sub-Catagories-13          29974 non-null  category\n",
      " 18  sub-Catagories-14          29974 non-null  category\n",
      " 19  sub-Catagories-15          29974 non-null  category\n",
      " 20  sub-Catagories-16          29974 non-null  category\n",
      " 21  sub-Catagories-17          29974 non-null  category\n",
      " 22  sub-Catagories-18          29974 non-null  category\n",
      " 23  sub-Catagories-19          29974 non-null  category\n",
      " 24  sub-Catagories-20          29974 non-null  category\n",
      " 25  sub-Catagories-21          29974 non-null  category\n",
      " 26  sub-Catagories-22          29974 non-null  category\n",
      " 27  sub-Catagories-23          29974 non-null  category\n",
      " 28  sub-Catagories-24          29974 non-null  category\n",
      " 29  sub-Catagories-25          29974 non-null  category\n",
      " 30  sub-Catagories-26          29974 non-null  category\n",
      " 31  Avg_Price_By_Brand         29974 non-null  float64 \n",
      " 32  Avg_Price_By_Brand_Colour  29974 non-null  float64 \n",
      " 33  Category_Count             29974 non-null  int64   \n",
      "dtypes: category(28), float64(2), int64(2), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to train, validation, test and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(data, target_column, train_size=0.7, validation_size=0.2, test_size=0.1, stratify=None):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into train, validation, and test sets, and returns features and target as NumPy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): The input DataFrame to be split.\n",
    "    target_column (str): The name of the target column.\n",
    "    train_size (float): Proportion of the dataset to include in the train split (0 to 1).\n",
    "    validation_size (float): Proportion of the dataset to include in the validation split (0 to 1).\n",
    "    test_size (float): Proportion of the dataset to include in the test split (0 to 1).\n",
    "    stratify (str or None): Column to be used for stratification. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "    x_train (ndarray): Training set features.\n",
    "    y_train (ndarray): Training set target.\n",
    "    x_validation (ndarray): Validation set features.\n",
    "    y_validation (ndarray): Validation set target.\n",
    "    x_test (ndarray): Test set features.\n",
    "    y_test (ndarray): Test set target.\n",
    "\n",
    "    Example:\n",
    "    >>> import pandas as pd\n",
    "    >>> data = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                'Feature1': [0.1, 0.2, 0.2, 0.4, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "                'Feature2': [1.1, 1.2, 1.2, 1.4, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9],\n",
    "                'Target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]}\n",
    "    >>> df = pd.DataFrame(data)\n",
    "    >>> x_train, y_train, x_validation, y_validation, x_test, y_test = split_dataframe(df, target_column='Target', stratify='Target')\n",
    "    >>> print(x_train.shape, y_train.shape)\n",
    "    >>> print(x_validation.shape, y_validation.shape)\n",
    "    >>> print(x_test.shape, y_test.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stratify parameter for the split (can be None)\n",
    "    stratify_param = None\n",
    "    if stratify is not None:\n",
    "        stratify_param = data[stratify]\n",
    "    \n",
    "    # Convert DataFrame to a dictionary of records\n",
    "    data_dict = data.drop(columns=[target_column, 'ID', 'Name']).to_dict(orient=\"records\")\n",
    "    \n",
    "    # Vectorize the dictionary of records\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "    data_features = vec.fit_transform(data_dict)\n",
    "    \n",
    "    # Split the feature matrix and target array into train+validation and test sets\n",
    "    train_validation_features, test_features, train_validation_target, test_target = train_test_split(\n",
    "        data_features, data[target_column].values, test_size=test_size, random_state=42, stratify=stratify_param\n",
    "    )\n",
    "    \n",
    "    if validation_size == 0:\n",
    "        x_train = train_validation_features\n",
    "        y_train = train_validation_target\n",
    "        x_validation, y_validation = None, None\n",
    "    else:\n",
    "        # Adjust validation size to account for the test set already being removed\n",
    "        adjusted_validation_size = validation_size / (1 - test_size)\n",
    "        \n",
    "        # Split the remaining data into train and validation sets\n",
    "        x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "            train_validation_features, train_validation_target, test_size=adjusted_validation_size, random_state=42, stratify=stratify_param\n",
    "        )\n",
    "    \n",
    "    x_test = test_features\n",
    "    y_test = test_target\n",
    "    \n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_validation, y_validation, x_test, y_test = split_dataframe(df, target_column='Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Rattapon.San/Fashion-rental-prediction-with-mlops/notebook/mlruns/1', creation_time=1721804795289, experiment_id='1', last_update_time=1721804795289, lifecycle_stage='active', name='fashion-rental-prediction', tags={}>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"fashion-rental-prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, BayesianRidge, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "bayesian = BayesianRidge()\n",
    "sgd = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # enable autologging\n",
    "# for model in tqdm((lasso, bayesian, sgd), desc = 'Training with sklearn model'):\n",
    "#     mlflow.sklearn.autolog()\n",
    "#     with mlflow.start_run() as run:\n",
    "#         model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_regressor\n",
    "from hyperopt import tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator(regressor=any_regressor(name='test'), trial_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ทำใหม่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:10<00:00, 130.57s/trial, best loss=?]\n"
     ]
    },
    {
     "ename": "AllTrialsFailed",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAllTrialsFailed\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mestim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hpsklearn\\estimator\\estimator.py:480\u001b[0m, in \u001b[0;36mhyperopt_estimator.fit\u001b[1;34m(self, X, y, EX_list, valid_size, n_folds, kfolds_group, cv_shuffle, warm_start, random_state)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     increment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_increment,\n\u001b[0;32m    479\u001b[0m                     adjusted_max_evals \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m--> 480\u001b[0m     \u001b[43mfit_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_increment_dump_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_increment_dump_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dump_file:\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hpsklearn\\estimator\\estimator.py:347\u001b[0m, in \u001b[0;36mhyperopt_estimator.fit_iter\u001b[1;34m(self, X, y, EX_list, valid_size, n_folds, kfolds_group, cv_shuffle, warm_start, random_state)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# Workaround for rstate issue #35\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrstate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetfullargspec(hyperopt\u001b[38;5;241m.\u001b[39mfmin)\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m--> 347\u001b[0m     \u001b[43mhyperopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fn_with_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# -- let exceptions crash the program, so we notice them.\u001b[39;49;00m\n\u001b[0;32m    353\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# -- in case no success so far\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hyperopt\\fmin.py:597\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trials\u001b[38;5;241m.\u001b[39margmin\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Only if there are some successful trail runs, return the best point in\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# the evaluation space\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m space_eval(space, \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hyperopt\\base.py:620\u001b[0m, in \u001b[0;36mTrials.argmin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margmin\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 620\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\n\u001b[0;32m    621\u001b[0m     vals \u001b[38;5;241m=\u001b[39m best_trial[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmisc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;66;03m# unpack the one-element lists to values\u001b[39;00m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;66;03m# and skip over the 0-element lists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rattapon.San\\AppData\\Local\\miniconda3\\envs\\fashion-rental-prediction\\Lib\\site-packages\\hyperopt\\base.py:611\u001b[0m, in \u001b[0;36mTrials.best_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    606\u001b[0m     t\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m STATUS_OK \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    609\u001b[0m ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AllTrialsFailed\n\u001b[0;32m    612\u001b[0m losses \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAllTrialsFailed\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estim.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-rental-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
